{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4aed2b59",
   "metadata": {},
   "source": [
    "# Turkish Earthquake Clustering Analysis\n",
    "\n",
    "This notebook implements unsupervised learning techniques to identify earthquake patterns and risk zones using our processed AFAD earthquake dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4e90a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import folium\n",
    "from folium.plugins import HeatMap, MarkerCluster\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import joblib\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# Set visualization settings\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('viridis')\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "# Load the clean earthquake dataset with original coordinates\n",
    "earthquake_df = pd.read_csv('clean_earthquake_data.csv')\n",
    "\n",
    "# Verify coordinate range\n",
    "print(f\"Dataset shape: {earthquake_df.shape}\")\n",
    "print(f\"Coordinate ranges:\")\n",
    "print(f\"Longitude: {earthquake_df['Longitude'].min():.2f} to {earthquake_df['Longitude'].max():.2f}\")\n",
    "print(f\"Latitude: {earthquake_df['Latitude'].min():.2f} to {earthquake_df['Latitude'].max():.2f}\")\n",
    "\n",
    "earthquake_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f873bb2",
   "metadata": {},
   "source": [
    "## 1. Data Preparation for Clustering\n",
    "\n",
    "Selecting and preparing relevant features for clustering algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadc5fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features for clustering\n",
    "# Geographic and physical features are most relevant for spatial clustering\n",
    "clustering_features = ['Longitude', 'Latitude', 'Depth', 'Magnitude']\n",
    "\n",
    "# Create a subset of data for clustering\n",
    "cluster_data = earthquake_df[clustering_features].copy()\n",
    "\n",
    "# Check for missing values\n",
    "print(\"Missing values in clustering features:\")\n",
    "print(cluster_data.isnull().sum())\n",
    "\n",
    "# Fill any missing values if needed\n",
    "cluster_data.fillna(cluster_data.median(), inplace=True)\n",
    "\n",
    "# Standardize features for clustering algorithms\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(cluster_data)\n",
    "scaled_df = pd.DataFrame(scaled_data, columns=clustering_features)\n",
    "\n",
    "print(\"Data prepared for clustering:\")\n",
    "scaled_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9a1cbc",
   "metadata": {},
   "source": [
    "## 2. K-Means Clustering\n",
    "\n",
    "Using K-Means to identify distinct earthquake zones based on location and characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf86d87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine optimal number of clusters using the Elbow Method\n",
    "inertia = []\n",
    "silhouette_scores = []\n",
    "k_range = range(2, 12)\n",
    "\n",
    "for k in k_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans.fit(scaled_data)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "    \n",
    "    # Compute silhouette score\n",
    "    labels = kmeans.labels_\n",
    "    silhouette_avg = silhouette_score(scaled_data, labels)\n",
    "    silhouette_scores.append(silhouette_avg)\n",
    "    \n",
    "    print(f\"K={k}, Inertia={kmeans.inertia_:.2f}, Silhouette Score={silhouette_avg:.3f}\")\n",
    "\n",
    "# Plot the Elbow Method results\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(k_range, inertia, 'o-')\n",
    "plt.xlabel('Number of Clusters (k)')\n",
    "plt.ylabel('Inertia')\n",
    "plt.title('Elbow Method for Optimal k')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(k_range, silhouette_scores, 'o-')\n",
    "plt.xlabel('Number of Clusters (k)')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.title('Silhouette Analysis for Optimal k')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Select the optimal k based on the elbow method and silhouette score\n",
    "optimal_k = 5  # You should adjust this based on the plots\n",
    "\n",
    "# Apply K-Means with the optimal number of clusters\n",
    "kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
    "cluster_labels = kmeans.fit_predict(scaled_data)\n",
    "\n",
    "# Add cluster labels to the original dataframe\n",
    "earthquake_df['KMeans_Cluster'] = cluster_labels\n",
    "\n",
    "# Display the distribution of clusters\n",
    "plt.figure(figsize=(10, 6))\n",
    "cluster_counts = earthquake_df['KMeans_Cluster'].value_counts().sort_index()\n",
    "cluster_counts.plot(kind='bar')\n",
    "plt.xlabel('Cluster')\n",
    "plt.ylabel('Number of Earthquakes')\n",
    "plt.title('Distribution of Earthquakes Across K-Means Clusters')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0db857",
   "metadata": {},
   "source": [
    "## 3. Visualizing K-Means Clusters\n",
    "\n",
    "Exploring the geographical and characteristic distribution of the identified clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c40eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze cluster characteristics\n",
    "cluster_analysis = earthquake_df.groupby('KMeans_Cluster').agg({\n",
    "    'Longitude': 'mean',\n",
    "    'Latitude': 'mean',\n",
    "    'Depth': 'mean',\n",
    "    'Magnitude': 'mean',\n",
    "    'KMeans_Cluster': 'count'\n",
    "}).rename(columns={'KMeans_Cluster': 'Count'})\n",
    "\n",
    "print(\"Cluster characteristics:\")\n",
    "print(cluster_analysis)\n",
    "\n",
    "# Create K-means map visualization with folium - FIXED coordinates\n",
    "kmeans_map = folium.Map(location=[38.5, 35.5], zoom_start=6)\n",
    "\n",
    "# Create a discrete color map for clusters\n",
    "cluster_colors = ['red', 'blue', 'green', 'purple', 'orange', 'darkred', 'darkblue', 'cadetblue']\n",
    "\n",
    "# Add clusters as markers, ensuring coordinates are within Turkey's boundaries\n",
    "for idx, row in earthquake_df.sample(min(5000, len(earthquake_df))).iterrows():\n",
    "    cluster_idx = int(row['KMeans_Cluster']) % len(cluster_colors)\n",
    "    color = cluster_colors[cluster_idx]\n",
    "    \n",
    "    folium.CircleMarker(\n",
    "        location=[row['Latitude'], row['Longitude']],  # Latitude first, Longitude second\n",
    "        radius=3 + (row['Magnitude'] - 4)/2,  # Size based on magnitude\n",
    "        color=color,\n",
    "        fill=True,\n",
    "        fill_color=color,\n",
    "        fill_opacity=0.7,\n",
    "        popup=f\"Cluster: {row['KMeans_Cluster']}<br>Magnitude: {row['Magnitude']}\"\n",
    "    ).add_to(kmeans_map)\n",
    "\n",
    "# Add cluster centers as larger markers\n",
    "for cluster_id, group in earthquake_df.groupby('KMeans_Cluster'):\n",
    "    center_lat = group['Latitude'].mean()\n",
    "    center_lon = group['Longitude'].mean()\n",
    "    cluster_idx = int(cluster_id) % len(cluster_colors)\n",
    "    color = cluster_colors[cluster_idx]\n",
    "    \n",
    "    folium.CircleMarker(\n",
    "        location=[center_lat, center_lon],  # Latitude first, Longitude second\n",
    "        radius=8,\n",
    "        color='black',\n",
    "        fill=True,\n",
    "        fill_color=color,\n",
    "        fill_opacity=0.9,\n",
    "        popup=f\"Cluster Center {cluster_id}\"\n",
    "    ).add_to(kmeans_map)\n",
    "\n",
    "# Add better tile layer\n",
    "folium.TileLayer('cartodbpositron').add_to(kmeans_map)\n",
    "\n",
    "# Save the map\n",
    "kmeans_map.save('kmeans_clusters_map.html')\n",
    "print(\"K-means cluster map saved as 'kmeans_clusters_map.html'\")\n",
    "\n",
    "# Also create a Plotly version for the notebook - FIXED\n",
    "fig_kmeans = px.scatter_mapbox(\n",
    "    earthquake_df.sample(min(3000, len(earthquake_df))), \n",
    "    lat='Latitude',  # Ensure correct parameter for latitude \n",
    "    lon='Longitude',  # Ensure correct parameter for longitude\n",
    "    color='KMeans_Cluster',\n",
    "    size='Magnitude',\n",
    "    color_continuous_scale=px.colors.qualitative.Bold,\n",
    "    size_max=15,\n",
    "    zoom=5,\n",
    "    center={\"lat\": 38.5, \"lon\": 35.5},  # Centered on Turkey\n",
    "    mapbox_style=\"open-street-map\",\n",
    "    title='K-Means Clusters of Turkish Earthquakes',\n",
    "    hover_data=['Depth', 'Magnitude', 'KMeans_Cluster']\n",
    ")\n",
    "fig_kmeans.update_layout(margin={\"r\":0,\"t\":40,\"l\":0,\"b\":0})\n",
    "fig_kmeans.write_html('kmeans_clusters_map_plotly.html')\n",
    "\n",
    "# Create a 3D scatter plot of clusters - FIXED\n",
    "fig = px.scatter_3d(\n",
    "    earthquake_df, \n",
    "    x='Longitude', \n",
    "    y='Latitude', \n",
    "    z='Depth',\n",
    "    color='KMeans_Cluster', \n",
    "    size='Magnitude',\n",
    "    color_continuous_scale=px.colors.qualitative.G10,\n",
    "    title='3D Visualization of Earthquake Clusters'\n",
    ")\n",
    "# Ensure proper axis orientation and labels\n",
    "fig.update_layout(scene=dict(\n",
    "    xaxis_title='Longitude',\n",
    "    yaxis_title='Latitude',\n",
    "    zaxis_title='Depth (km)',\n",
    "    zaxis=dict(autorange=\"reversed\")  # Reverse depth axis so deeper is lower\n",
    "))\n",
    "fig.write_html('kmeans_clusters_3d.html')\n",
    "\n",
    "# Create a pairplot to visualize cluster separation\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.pairplot(earthquake_df[clustering_features + ['KMeans_Cluster']], \n",
    "             hue='KMeans_Cluster', palette='viridis')\n",
    "plt.suptitle('Pairwise Feature Relationships by Cluster', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0c470a",
   "metadata": {},
   "source": [
    "## 4. DBSCAN Clustering\n",
    "\n",
    "Using DBSCAN to identify dense clusters and potential outliers in earthquake data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50ca231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply DBSCAN clustering\n",
    "# We need to find appropriate epsilon and min_samples values\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Determine epsilon using k-distance graph\n",
    "neighbors = NearestNeighbors(n_neighbors=20)\n",
    "neighbors_fit = neighbors.fit(scaled_data)\n",
    "distances, indices = neighbors_fit.kneighbors(scaled_data)\n",
    "\n",
    "# Sort distances for k-distance graph\n",
    "distances = np.sort(distances, axis=0)\n",
    "distances = distances[:, 19]  # 20th neighbor\n",
    "\n",
    "# Plot k-distance graph\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(distances)\n",
    "plt.xlabel('Points sorted by distance')\n",
    "plt.ylabel('20th Nearest Neighbor Distance')\n",
    "plt.title('K-Distance Graph for DBSCAN Epsilon Selection')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Based on the k-distance plot, choose an appropriate epsilon\n",
    "# Look for the \"elbow\" in the plot\n",
    "epsilon = 0.5  # Adjust based on the plot\n",
    "min_samples = 20  # Minimum neighbors for a core point\n",
    "\n",
    "# Apply DBSCAN with chosen parameters\n",
    "dbscan = DBSCAN(eps=epsilon, min_samples=min_samples)\n",
    "dbscan_labels = dbscan.fit_predict(scaled_data)\n",
    "\n",
    "# Add DBSCAN labels to the dataframe\n",
    "earthquake_df['DBSCAN_Cluster'] = dbscan_labels\n",
    "\n",
    "# Count the number of clusters and noise points\n",
    "n_clusters = len(set(dbscan_labels)) - (1 if -1 in dbscan_labels else 0)\n",
    "n_noise = list(dbscan_labels).count(-1)\n",
    "\n",
    "print(f\"DBSCAN found {n_clusters} clusters and {n_noise} noise points.\")\n",
    "print(f\"Percentage of noise points: {n_noise / len(dbscan_labels) * 100:.2f}%\")\n",
    "\n",
    "# Display the distribution of DBSCAN clusters\n",
    "plt.figure(figsize=(12, 6))\n",
    "cluster_counts = earthquake_df['DBSCAN_Cluster'].value_counts().sort_index()\n",
    "cluster_counts.plot(kind='bar')\n",
    "plt.xlabel('Cluster')\n",
    "plt.ylabel('Number of Earthquakes')\n",
    "plt.title('Distribution of Earthquakes Across DBSCAN Clusters')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfa43c8",
   "metadata": {},
   "source": [
    "## 5. Visualizing DBSCAN Clusters\n",
    "\n",
    "Mapping the DBSCAN clusters to identify high-density earthquake zones and outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e7ba0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DBSCAN map visualization with folium\n",
    "dbscan_map = folium.Map(location=[38.5, 35.5], zoom_start=6)\n",
    "\n",
    "# Number of clusters excluding noise\n",
    "num_clusters = len(set(earthquake_df['DBSCAN_Cluster'])) - (1 if -1 in earthquake_df['DBSCAN_Cluster'].values else 0)\n",
    "colormap = cm.get_cmap('tab20', max(num_clusters + 1, 2))  # +1 for noise points\n",
    "\n",
    "# Function to get color for cluster\n",
    "def get_cluster_color(cluster_id):\n",
    "    if cluster_id == -1:  # Noise points\n",
    "        return '#000000'  # Black\n",
    "    else:\n",
    "        rgba = colormap(cluster_id % max(num_clusters, 1))\n",
    "        return mcolors.rgb2hex(rgba)\n",
    "\n",
    "# Add data points with proper colors (sample for performance)\n",
    "for idx, row in earthquake_df.sample(min(5000, len(earthquake_df))).iterrows():\n",
    "    cluster_id = int(row['DBSCAN_Cluster'])\n",
    "    color = get_cluster_color(cluster_id)\n",
    "    \n",
    "    folium.CircleMarker(\n",
    "        location=[row['Latitude'], row['Longitude']],  # Latitude first, then Longitude\n",
    "        radius=3 + (row['Magnitude'] - 4)/2,\n",
    "        color=color,\n",
    "        fill=True,\n",
    "        fill_color=color,\n",
    "        fill_opacity=0.7 if cluster_id != -1 else 0.3,  # Make noise points more transparent\n",
    "        popup=f\"Cluster: {cluster_id}<br>Magnitude: {row['Magnitude']}\"\n",
    "    ).add_to(dbscan_map)\n",
    "\n",
    "# Add better tile layer\n",
    "folium.TileLayer('cartodbpositron').add_to(dbscan_map)\n",
    "\n",
    "# Save the map\n",
    "dbscan_map.save('dbscan_clusters_map.html')\n",
    "print(\"DBSCAN cluster map saved as 'dbscan_clusters_map.html'\")\n",
    "\n",
    "# Also create a Plotly version for the notebook - FIXED\n",
    "fig_dbscan = px.scatter_mapbox(\n",
    "    earthquake_df.sample(min(3000, len(earthquake_df))), \n",
    "    lat='Latitude',  # Correct parameter for latitude\n",
    "    lon='Longitude',  # Correct parameter for longitude\n",
    "    color='DBSCAN_Cluster',\n",
    "    size='Magnitude',\n",
    "    color_continuous_scale=px.colors.qualitative.Dark24,\n",
    "    size_max=15,\n",
    "    zoom=5,\n",
    "    center={\"lat\": 38.5, \"lon\": 35.5},  # Centered on Turkey\n",
    "    mapbox_style=\"open-street-map\",\n",
    "    title='DBSCAN Clusters of Turkish Earthquakes',\n",
    "    hover_data=['Depth', 'Magnitude', 'DBSCAN_Cluster']\n",
    ")\n",
    "fig_dbscan.update_layout(margin={\"r\":0,\"t\":40,\"l\":0,\"b\":0})\n",
    "fig_dbscan.write_html('dbscan_clusters_map_plotly.html')\n",
    "\n",
    "# Create density heatmap with Plotly - FIXED\n",
    "fig_density = px.density_mapbox(\n",
    "    earthquake_df, \n",
    "    lat='Latitude',  # Correct parameter for latitude\n",
    "    lon='Longitude',  # Correct parameter for longitude\n",
    "    z='Magnitude',\n",
    "    radius=10,\n",
    "    zoom=5, \n",
    "    center={\"lat\": 38.5, \"lon\": 35.5},  # Centered on Turkey\n",
    "    mapbox_style=\"open-street-map\",\n",
    "    title='Earthquake Density Heatmap'\n",
    ")\n",
    "fig_density.update_layout(margin={\"r\":0,\"t\":40,\"l\":0,\"b\":0})\n",
    "fig_density.write_html('earthquake_density_map.html')\n",
    "\n",
    "# Analyze DBSCAN cluster characteristics\n",
    "dbscan_analysis = earthquake_df[earthquake_df['DBSCAN_Cluster'] != -1].groupby('DBSCAN_Cluster').agg({\n",
    "    'Longitude': 'mean',\n",
    "    'Latitude': 'mean',\n",
    "    'Depth': 'mean',\n",
    "    'Magnitude': 'mean',\n",
    "    'DBSCAN_Cluster': 'count'\n",
    "}).rename(columns={'DBSCAN_Cluster': 'Count'})\n",
    "\n",
    "print(\"DBSCAN cluster characteristics (excluding noise):\")\n",
    "print(dbscan_analysis)\n",
    "\n",
    "# Noise point characteristics\n",
    "noise_points = earthquake_df[earthquake_df['DBSCAN_Cluster'] == -1]\n",
    "print(\"\\nNoise point characteristics:\")\n",
    "print(noise_points[['Longitude', 'Latitude', 'Depth', 'Magnitude']].describe())\n",
    "\n",
    "# Create a 3D scatter plot of DBSCAN clusters - FIXED\n",
    "fig = px.scatter_3d(\n",
    "    earthquake_df, \n",
    "    x='Longitude', \n",
    "    y='Latitude', \n",
    "    z='Depth',\n",
    "    color='DBSCAN_Cluster', \n",
    "    size='Magnitude',\n",
    "    color_continuous_scale=px.colors.qualitative.G10,\n",
    "    title='3D Visualization of DBSCAN Earthquake Clusters'\n",
    ")\n",
    "# Ensure proper axis orientation and labels\n",
    "fig.update_layout(scene=dict(\n",
    "    xaxis_title='Longitude',\n",
    "    yaxis_title='Latitude',\n",
    "    zaxis_title='Depth (km)',\n",
    "    zaxis=dict(autorange=\"reversed\")  # Reverse depth axis so deeper is lower\n",
    "))\n",
    "fig.write_html('dbscan_clusters_3d.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e0d167",
   "metadata": {},
   "source": [
    "## 6. Dimensionality Reduction with PCA\n",
    "\n",
    "Using PCA to visualize high-dimensional earthquake data in 2D space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308893c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply PCA for dimensionality reduction\n",
    "pca = PCA(n_components=2)\n",
    "pca_result = pca.fit_transform(scaled_data)\n",
    "\n",
    "# Create a DataFrame with PCA results\n",
    "pca_df = pd.DataFrame(data=pca_result, columns=['PC1', 'PC2'])\n",
    "pca_df['KMeans_Cluster'] = earthquake_df['KMeans_Cluster']\n",
    "pca_df['DBSCAN_Cluster'] = earthquake_df['DBSCAN_Cluster']\n",
    "pca_df['Magnitude'] = earthquake_df['Magnitude']\n",
    "\n",
    "# Explained variance ratio\n",
    "print(\"Explained variance ratio:\")\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(f\"Total explained variance: {sum(pca.explained_variance_ratio_) * 100:.2f}%\")\n",
    "\n",
    "# Visualize PCA results with K-Means clusters\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.subplot(2, 1, 1)\n",
    "sns.scatterplot(data=pca_df, x='PC1', y='PC2', hue='KMeans_Cluster', palette='viridis', \n",
    "                size='Magnitude', sizes=(20, 200), alpha=0.6)\n",
    "plt.title('PCA of Earthquake Data with K-Means Clusters')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Visualize PCA results with DBSCAN clusters\n",
    "plt.subplot(2, 1, 2)\n",
    "sns.scatterplot(data=pca_df, x='PC1', y='PC2', hue='DBSCAN_Cluster', palette='viridis', \n",
    "                size='Magnitude', sizes=(20, 200), alpha=0.6)\n",
    "plt.title('PCA of Earthquake Data with DBSCAN Clusters')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Feature loadings on principal components\n",
    "loadings = pd.DataFrame(\n",
    "    pca.components_.T, \n",
    "    columns=['PC1', 'PC2'],\n",
    "    index=clustering_features\n",
    ")\n",
    "\n",
    "print(\"\\nPCA Feature Loadings:\")\n",
    "print(loadings)\n",
    "\n",
    "# Visualize the feature loadings\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.bar(loadings.index, loadings['PC1'], alpha=0.7, label='PC1')\n",
    "plt.bar(loadings.index, loadings['PC2'], alpha=0.7, label='PC2')\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Loading Strength')\n",
    "plt.title('PCA Feature Loadings')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39308bca",
   "metadata": {},
   "source": [
    "## 7. Risk Zone Identification\n",
    "\n",
    "Using clustering results to identify high-risk earthquake zones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17715318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine clustering information with magnitude to identify risk zones\n",
    "earthquake_df['Risk_Score'] = 0\n",
    "\n",
    "# Calculate risk score based on:\n",
    "# 1. Magnitude\n",
    "# 2. Cluster density\n",
    "# 3. Historical frequency\n",
    "\n",
    "# Scale magnitude to 0-10 range (assuming most are between 4-8)\n",
    "earthquake_df['Magnitude_Score'] = (earthquake_df['Magnitude'] - 4) * 2.5\n",
    "earthquake_df['Magnitude_Score'] = earthquake_df['Magnitude_Score'].clip(0, 10)\n",
    "\n",
    "# Calculate density of clusters (earthquakes per area)\n",
    "# First, verify we have valid coordinate ranges to avoid division by zero\n",
    "kmeans_spatial_range = earthquake_df.groupby('KMeans_Cluster').agg({\n",
    "    'Longitude': lambda x: max(x) - min(x),\n",
    "    'Latitude': lambda x: max(x) - min(x)\n",
    "})\n",
    "\n",
    "# Ensure we don't divide by zero by adding a small value\n",
    "kmeans_spatial_range = kmeans_spatial_range + 0.001  # Add small value to prevent division by zero\n",
    "\n",
    "# Now calculate density safely\n",
    "kmeans_density = earthquake_df.groupby('KMeans_Cluster').size() / kmeans_spatial_range.prod(axis=1)\n",
    "\n",
    "# Normalize density to 0-10 scale\n",
    "max_density = kmeans_density.max()\n",
    "if max_density > 0:  # Avoid division by zero\n",
    "    normalized_density = (kmeans_density / max_density) * 10\n",
    "else:\n",
    "    normalized_density = kmeans_density * 0  # All zeros if max_density is 0\n",
    "\n",
    "# Map density scores back to dataframe\n",
    "density_map = dict(zip(normalized_density.index, normalized_density.values))\n",
    "earthquake_df['Density_Score'] = earthquake_df['KMeans_Cluster'].map(density_map)\n",
    "\n",
    "# Calculate final risk score (weighted average)\n",
    "earthquake_df['Risk_Score'] = (\n",
    "    earthquake_df['Magnitude_Score'] * 0.5 + \n",
    "    earthquake_df['Density_Score'] * 0.5\n",
    ")\n",
    "\n",
    "# Classify risk zones\n",
    "earthquake_df['Risk_Zone'] = pd.cut(\n",
    "    earthquake_df['Risk_Score'], \n",
    "    bins=[0, 3, 6, 10], \n",
    "    labels=['Low', 'Medium', 'High']\n",
    ")\n",
    "\n",
    "# Display risk zone distribution\n",
    "risk_distribution = earthquake_df['Risk_Zone'].value_counts()\n",
    "print(\"Risk Zone Distribution:\")\n",
    "print(risk_distribution)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "risk_distribution.plot(kind='bar', color=['green', 'yellow', 'red'])\n",
    "plt.title('Distribution of Earthquake Risk Zones')\n",
    "plt.xlabel('Risk Zone')\n",
    "plt.ylabel('Number of Earthquakes')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Create a risk zone map with folium - FIXED\n",
    "risk_map = folium.Map(location=[38.5, 35.5], zoom_start=6)\n",
    "\n",
    "# Color mapping for risk zones\n",
    "risk_colors = {\n",
    "    'Low': 'green',\n",
    "    'Medium': 'orange',\n",
    "    'High': 'red'\n",
    "}\n",
    "\n",
    "# Create separate marker clusters for each risk zone\n",
    "marker_clusters = {\n",
    "    'Low': folium.plugins.MarkerCluster(name='Low Risk').add_to(risk_map),\n",
    "    'Medium': folium.plugins.MarkerCluster(name='Medium Risk').add_to(risk_map),\n",
    "    'High': folium.plugins.MarkerCluster(name='High Risk').add_to(risk_map)\n",
    "}\n",
    "\n",
    "# Sample data points to avoid performance issues\n",
    "sampled_data = earthquake_df.sample(min(5000, len(earthquake_df)))\n",
    "\n",
    "# Add markers colored by risk zone\n",
    "for idx, row in sampled_data.iterrows():\n",
    "    risk_zone = row['Risk_Zone']\n",
    "    folium.CircleMarker(\n",
    "        location=[row['Latitude'], row['Longitude']],  # Latitude first, then Longitude\n",
    "        radius=3 + (row['Magnitude'] - 4)/2,\n",
    "        color=risk_colors[risk_zone],\n",
    "        fill=True,\n",
    "        fill_color=risk_colors[risk_zone],\n",
    "        fill_opacity=0.7,\n",
    "        popup=f\"Risk: {risk_zone}<br>Score: {row['Risk_Score']:.2f}<br>Magnitude: {row['Magnitude']}\"\n",
    "    ).add_to(marker_clusters[risk_zone])\n",
    "\n",
    "# Add better tile layer\n",
    "folium.TileLayer('cartodbpositron').add_to(risk_map)\n",
    "\n",
    "# Add layer control\n",
    "folium.LayerControl().add_to(risk_map)\n",
    "\n",
    "# Save risk map to HTML file\n",
    "risk_map.save('earthquake_risk_map.html')\n",
    "print(\"Risk zone map saved as 'earthquake_risk_map.html'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde563db",
   "metadata": {},
   "source": [
    "## 8. Conclusion and Findings\n",
    "\n",
    "Summary of unsupervised learning insights and risk zone identification results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60dc353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the clustering results\n",
    "earthquake_df.to_csv('earthquake_clusters.csv', index=False)\n",
    "\n",
    "# Summarize cluster and risk zone characteristics\n",
    "cluster_risk_summary = earthquake_df.groupby(['KMeans_Cluster', 'Risk_Zone']).agg({\n",
    "    'Magnitude': ['mean', 'min', 'max', 'count'],\n",
    "    'Depth': ['mean', 'min', 'max'],\n",
    "    'Risk_Score': ['mean', 'min', 'max']\n",
    "})\n",
    "\n",
    "print(\"Cluster and Risk Zone Summary:\")\n",
    "print(cluster_risk_summary)\n",
    "\n",
    "# Final visualization: Risk zones by longitude/latitude - FIXED\n",
    "plt.figure(figsize=(12, 8))\n",
    "scatter = plt.scatter(\n",
    "    earthquake_df['Longitude'],  # X-axis is Longitude\n",
    "    earthquake_df['Latitude'],   # Y-axis is Latitude\n",
    "    c=earthquake_df['Risk_Score'],\n",
    "    cmap='RdYlGn_r',  # Red for high risk, green for low risk\n",
    "    alpha=0.7,\n",
    "    s=20\n",
    ")\n",
    "plt.colorbar(scatter, label='Risk Score')\n",
    "plt.title('Earthquake Risk Zones in Turkey')\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('earthquake_risk_zones.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(\"Unsupervised learning analysis completed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
